{
  "version": "0.1.20",
  "git_url": "https://github.com/OCR-D/ocrd_segment",
  "tools": {
    "ocrd-segment-extract-formdata": {
      "executable": "ocrd-segment-extract-formdata",
      "categories": ["Image preprocessing"],
      "description": "Extract page segmentation as page images (deskewed according to `/Page/@orientation` and cropped+masked along `/Page/Border`) and as JSON (including region coordinates/classes and meta-data) + COCO detection format JSON (for all pages) [for mrcnn input/context and output/target]. Output fileGrp format is `image,json`.",
      "input_file_grp": [
        "OCR-D-SEG-LINE",
        "OCR-D-GT-SEG-LINE",
        "OCR-D-OCR"
      ],
      "output_file_grp": [
        "IMG-ADDR",
        "JSON-ADDR"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
        "source": {
          "type": "string",
          "default": "Sonstige",
          "enum": ["Sonstige", "Brunata", "Ista", "Techem", "BFW", "Kalo", "Minol"],
          "description": "Dataset source to annotate along with categories."
        }
      }
    },
    "ocrd-segment-extract-address": {
      "executable": "ocrd-segment-extract-address",
      "categories": ["Image preprocessing"],
      "description": "Extract page segmentation as page images (deskewed according to `/Page/@orientation` and cropped+masked along `/Page/Border`) with alpha channel color-coding textline masks [for mrcnn input], and as JSON (including region coordinates/classes and meta-data) + COCO detection format JSON (for all pages) [for mrcnn output]. Output fileGrp format is `image,json`.",
      "input_file_grp": [
        "OCR-D-SEG-LINE",
        "OCR-D-GT-SEG-LINE",
        "OCR-D-OCR"
      ],
      "output_file_grp": [
        "IMG-ADDR",
        "JSON-ADDR"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
        "categories": {
          "type": "array",
          "default": [{"id": 0,
                       "name": "BG",
                       "source": ""},
                      {"id": 1,
                       "name": "address-rcpt",
                       "source": "IAO",
                       "type": "paragraph"},
                      {"id": 2,
                       "name": "address-sndr",
                       "source": "IAO",
                       "type": "page-number"},
                      {"id": 3,
                       "name": "address-contact",
                       "source": "IAO",
                       "type": "marginalia"}],
          "description": "List of target classes in COCO format (dict with numeric `id`, string `name` and string `source`, string `type`). IDs may start with zero and collide with other data sources. Categories are extracted from `TextRegion/@type=type` if given or `TextRegion[@type=other]/@custom[substring-after(.,'subtype:')]` or `TextLine/@custom[substring-after(.,'subtype:')]` otherwise."
        }
      }
    },
    "ocrd-segment-classify-address-text": {
      "executable": "ocrd-segment-classify-address-text",
      "categories": ["Text recognition and optimization"],
      "description": "Classify OCR results of text lines into address parts (as context layer for address-layout), using @custom for marking.",
      "input_file_grp": [
        "OCR-D-OCR"
      ],
      "output_file_grp": [
        "OCR-D-OCR-ADDR"
      ],
      "steps": ["layout/segmentation/classification"],
      "parameters": {
        "num_processes": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 10,
          "description": "number of parallel processes when searching for address matches"
        },
        "glyph_conf_cutoff": {
          "type": "number",
          "format": "float",
          "minimum": 0.0,
          "maximum": 1.0,
          "default": 0.01,
          "description": "minimum probability of glyph OCR hypotheses to consider in string search"
        },
        "glyph_topn_cutoff": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 5,
          "description": "maximum number of glyph OCR hypotheses to consider in string search"
        },
        "line_topn_cutoff": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 20,
          "description": "maximum number of line OCR hypotheses to consider in string search"
        }
      }
    },
    "ocrd-segment-classify-address-layout": {
      "executable": "ocrd-segment-classify-address-layout",
      "categories": ["Layout analysis"],
      "description": "Find text regions that belong to addresses and classify them into sender/receiver/other (feeding context from address-text), using @custom for marking.",
      "input_file_grp": [
        "OCR-D-OCR-ADDR"
      ],
      "output_file_grp": [
        "OCR-D-SEG-ADDR"
      ],
      "steps": ["layout/segmentation/region"],
      "parameters": {
        "model": {
          "type": "string",
          "format": "uri",
          "content-type": "application/x-hdf;subtype=bag",
          "default": "address.h5",
          "description": "path of h5py weight file for model trained with address.py",
          "cacheable": true
        },
        "images_per_gpu": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 1,
          "description": "number of images fed in parallel (also equals number of CPU workers)"
        },
        "min_confidence": {
          "type": "number",
          "format": "float",
          "minimum": 0.0,
          "maximum": 1.0,
          "default": 0.5,
          "description": "minimum probability for region candidates"
        }
      }
    },
    "ocrd-segment-classify-formdata-dummy": {
      "executable": "ocrd-segment-classify-formdata-dummy",
      "categories": ["Layout analysis"],
      "description": "",
      "input_file_grp": [
        "OCR-D-OCR-FORMDATA"
      ],
      "output_file_grp": [
        "OCR-D-SEG-FORMDATA"
      ],
      "steps": ["layout/segmentation/region"],
      "parameters": {
        "categories": {
          "type": "array",
          "default": [],
          "description": "List of class names matching the list of (non-first) input fileGrps."
        },
        "context-type": {
          "type": "string",
          "enum": ["paragraph", "heading", "caption", "header", "footer", "page-number", "drop-capital", "credit", "floating", "signature-mark", "catch-word", "marginalia", "footnote", "footnote-continued", "endnote", "TOC-entry", "list-label", "other"],
          "default": "page-number",
          "description": "`TextRegion/@type` used to mark context [mrcnn input] regions."
        },
        "target-type": {
          "type": "string",
          "enum": ["paragraph", "heading", "caption", "header", "footer", "page-number", "drop-capital", "credit", "floating", "signature-mark", "catch-word", "marginalia", "footnote", "footnote-continued", "endnote", "TOC-entry", "list-label", "other"],
          "default": "paragraph",
          "description": "`TextRegion/@type` used to mark target [mrcnn output] regions."
        }
      }
    },
    "ocrd-segment-classify-formdata-text": {
      "executable": "ocrd-segment-classify-formdata-text",
      "categories": ["Text recognition and optimization"],
      "description": "Classify OCR results of text lines into context labels around form fields (as context layer for formdata-layout), using @custom for marking.",
      "input_file_grp": [
        "OCR-D-OCR-FORMDATA"
      ],
      "output_file_grp": [
        "OCR-D-SEG-FORMDATA"
      ],
      "steps": ["layout/segmentation/classification"],
      "parameters": {
        "num_processes": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 4,
          "description": "number of parallel processes when searching for keyword matches"
        },
        "threshold": {
          "type": "number",
          "format": "integer",
          "minimum": 0,
          "maximum": 100,
          "default": 90,
          "description": "minimum percentage of character/word match against pre-defined keywords"
        },
        "glyph_conf_cutoff": {
          "type": "number",
          "format": "float",
          "minimum": 0.0,
          "maximum": 1.0,
          "default": 0.01,
          "description": "minimum probability of glyph OCR hypotheses to consider in string search"
        },
        "glyph_topn_cutoff": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 5,
          "description": "maximum number of glyph OCR hypotheses to consider in string search"
        },
        "word_topn_cutoff": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 10,
          "description": "maximum number of word OCR hypotheses to consider in string search"
        },
        "line_topn_cutoff": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 100,
          "description": "maximum number of line OCR hypotheses to consider in string search"
        }
      }
    },
    "ocrd-segment-classify-formdata-layout": {
      "executable": "ocrd-segment-classify-formdata-layout",
      "categories": ["Layout analysis"],
      "description": "Find text regions that contain form fields for various classes (feeding context from formdata-text), using @custom for marking.",
      "input_file_grp": [
        "OCR-D-OCR-FORMDATA"
      ],
      "output_file_grp": [
        "OCR-D-SEG-FORMDATA"
      ],
      "steps": ["layout/segmentation/region"],
      "parameters": {
        "model": {
          "type": "string",
          "format": "uri",
          "content-type": "application/x-hdf;subtype=bag",
          "description": "path of h5py weight file for model trained with formdata.py",
          "cacheable": true
        },
        "images_per_gpu": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 1,
          "description": "number of images fed in parallel (also equals number of CPU workers)"
        },
        "num_processes": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 8,
          "description": "number of parallel processes when post-processing"
        },
        "min_confidence": {
          "type": "number",
          "format": "float",
          "minimum": 0.0,
          "maximum": 1.0,
          "default": 0.5,
          "description": "minimum probability for region candidates"
        }
      }
    },
    "ocrd-segment-postcorrect-formdata": {
      "executable": "ocrd-segment-postcorrect-formdata",
      "categories": ["Text recognition and optimization"],
      "description": "Decode OCR alternatives of text lines for form fields (from formdata-layout), trying to match predefined regular expressions for each class.",
      "input_file_grp": [
        "OCR-D-OCR-FORMDATA"
      ],
      "output_file_grp": [
        "OCR-D-COR-FORMDATA"
      ],
      "steps": ["recognition/post-correction"],
      "parameters": {
        "glyph_conf_cutoff": {
          "type": "number",
          "format": "float",
          "minimum": 0.0,
          "maximum": 1.0,
          "default": 0.01,
          "description": "minimum probability of glyph OCR hypotheses to consider in string search"
        },
        "glyph_topn_cutoff": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 5,
          "description": "maximum number of glyph OCR hypotheses to consider in string search"
        },
        "word_topn_cutoff": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 10,
          "description": "maximum number of word OCR hypotheses to consider in string search"
        },
        "line_topn_cutoff": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 100,
          "description": "maximum number of line OCR hypotheses to consider in string search"
        },
        "make_consistent": {
          "type": "boolean",
          "default": true,
          "description": "Search known pairs/groups of targets of locally valid results for consistent combinations if non-empty."
        }
      }
    },
    "ocrd-segment-repair": {
      "executable": "ocrd-segment-repair",
      "categories": ["Layout analysis"],
      "description": "Analyse and repair region segmentation; at least ensure validity and consistency of coordinates.",
      "input_file_grp": [
        "OCR-D-IMG",
        "OCR-D-SEG-BLOCK"
      ],
      "output_file_grp": [
        "OCR-D-SEG-BLOCK"
      ],
      "steps": ["layout/segmentation/region"],
      "parameters": {
        "simplify": {
          "type": "number",
          "format": "float",
          "minimum": 0,
          "default": 0,
          "description": "Distance (in px) used to simplify all segment polygons. (Avoid values larger than xheight/scale, or corners will be chopped off.) Set to 0 to disable."
        },
        "plausibilize": {
          "type": "boolean",
          "default": false,
          "description": "Identify and remove redundancies on text regions and text lines (deleting/merging/shrinking where overlaps occur)."
        },
        "plausibilize_merge_min_overlap": {
          "type": "number",
          "format": "float",
          "minimum": 0.0,
          "maximum": 1.0,
          "default": 0.90,
          "description": "When merging a region or line almost contained in another, require at least this ratio of area is shared with the other."
        },
        "sanitize": {
          "type": "boolean",
          "default": false,
          "description": "Shrink each region such that its coordinates become the minimal concave hull of its binary foreground. (Assumes that a perfect binarization is available.)"
        },
        "sanitize_padding": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 5,
          "description": "When shrinking a region, enlarge the resulting hull by this amount of pixels in each direction."
        }
      }
    },
    "ocrd-segment-project": {
      "executable": "ocrd-segment-project",
      "categories": ["Layout analysis"],
      "description": "Project segment coordinates to their structural parents",
      "input_file_grp": [
        "OCR-D-SEG-BLOCK"
      ],
      "output_file_grp": [
        "OCR-D-SEG-BLOCK"
      ],
      "steps": ["layout/segmentation"],
      "parameters": {
        "level-of-operation": {
          "type": "string",
          "enum": ["page", "table", "region", "line", "word"],
          "default": "page",
          "description": "hierarchy level which to assign new coordinates to"
        },
        "padding": {
          "type": "number",
          "format": "integer",
          "minimum": 0,
          "default": 10,
          "description": "margin (in px) to extend the hull in every direction"
        }
      }
    },
    "ocrd-segment-from-masks": {
      "executable": "ocrd-segment-from-masks",
      "categories": ["Layout analysis"],
      "description": "Import region segmentation from mask images (segments filled with colors encoding classes). Input fileGrp format is `base,mask` (i.e. PAGE or original image files first, mask image files second).",
      "input_file_grp": [
        "OCR-D-IMG",
        "OCR-D-SEG-PAGE"
      ],
      "output_file_grp": [
        "OCR-D-SEG-BLOCK"
      ],
      "steps": ["layout/segmentation/region"],
      "parameters": {
        "colordict": {
          "type": "object",
          "default": {
            "FFFFFF00": "",
            "FFFFFFFF": "Border",
            "8B4513FF": "TableRegion",
            "4682B4FF": "AdvertRegion",
            "FF8C00FF": "ChemRegion",
            "9400D3FF": "MusicRegion",
            "9ACDD2FF": "MapRegion",
            "0000FFFF": "TextRegion",
            "0000FFFA": "TextRegion:paragraph",
            "0000FFF5": "TextRegion:heading",
            "0000FFF0": "TextRegion:caption",
            "0000FFEB": "TextRegion:header",
            "0000FFE6": "TextRegion:footer",
            "0000FFE1": "TextRegion:page-number",
            "0000FFDC": "TextRegion:drop-capital",
            "0000FFD7": "TextRegion:credit",
            "0000FFD2": "TextRegion:floating",
            "0000FFCD": "TextRegion:signature-mark",
            "0000FFC8": "TextRegion:catch-word",
            "0000FFC3": "TextRegion:marginalia",
            "0000FFBE": "TextRegion:footnote",
            "0000FFB9": "TextRegion:footnote-continued",
            "0000FFB4": "TextRegion:endnote",
            "0000FFAF": "TextRegion:TOC-entry",
            "0000FFA5": "TextRegion:list-label",
            "0000FFA0": "TextRegion:other",
            "800080FF": "ChartRegion",
            "800080FA": "ChartRegion:bar",
            "800080F5": "ChartRegion:line",
            "800080F0": "ChartRegion:pie",
            "800080EB": "ChartRegion:scatter",
            "800080E6": "ChartRegion:surface",
            "800080E1": "ChartRegion:other",
            "008000FF": "GraphicRegion",
            "008000FA": "GraphicRegion:logo",
            "008000F0": "GraphicRegion:letterhead",
            "008000EB": "GraphicRegion:decoration",
            "008000E6": "GraphicRegion:frame",
            "008000E1": "GraphicRegion:handwritten-annotation",
            "008000DC": "GraphicRegion:stamp",
            "008000D7": "GraphicRegion:signature",
            "008000D2": "GraphicRegion:barcode",
            "008000CD": "GraphicRegion:paper-grow",
            "008000C8": "GraphicRegion:punch-hole",
            "008000C3": "GraphicRegion:other",
            "00CED1FF": "ImageRegion",
            "B8860BFF": "LineDrawingRegion",
            "00BFFFFF": "MathsRegion",
            "FF0000FF": "NoiseRegion",
            "FF00FFFF": "SeparatorRegion",
            "646464FF": "UnknownRegion",
            "637C81FF": "CustomRegion"},
          "description": "Mapping from color values in the input masks to region types to annotate; color must be encoded hexadecimal (e.g. '00FF00'); region type equals the element name in PAGE-XML, optionally followed by a colon and a subtype (e.g. 'TextRegion:paragraph'; unmapped colors will be ignored (i.e. treated as background)). Default is PageViewer color scheme. Cf. colordict.json output and colordict parameter of ocrd-segment-extract-pages."
        }
      }
    },
    "ocrd-segment-from-coco": {
      "executable": "ocrd-segment-from-coco",
      "categories": ["Layout analysis"],
      "description": "Import region segmentation from COCO detection format JSON (for all pages). Input fileGrp format is `base,COCO` (i.e. PAGE or original image files first, COCO file second).",
      "input_file_grp": [
        "OCR-D-IMG",
        "OCR-D-SEG-PAGE"
      ],
      "output_file_grp": [
        "OCR-D-SEG-BLOCK"
      ],
      "steps": ["layout/segmentation/region"],
      "parameters": {
        "categories": {
          "type": "object",
          "default": {},
          "description": "Mapping from COCO categories (or supercategories) to PAGE element identifiers (or subtypes) to apply before trying source mapping. (Example: {'image': 'ImageRegion', 'text': 'TextRegion'}.)"
        }
      }
    },
    "ocrd-segment-extract-pages": {
      "executable": "ocrd-segment-extract-pages",
      "categories": ["Image preprocessing"],
      "description": "Extract page segmentation as page images (deskewed according to `/Page/@orientation` and cropped+masked along `/Page/Border`) + JSON (including region coordinates/classes and meta-data), as binarized images, and as mask images (segments filled with colors encoding classes) + COCO detection format JSON (for all pages). Output fileGrp format is `raw[,binarized[,mask]]` (i.e. fall back to first group).",
      "input_file_grp": [
        "OCR-D-SEG-PAGE",
        "OCR-D-GT-SEG-PAGE",
        "OCR-D-SEG-BLOCK",
        "OCR-D-GT-SEG-BLOCK"
      ],
      "output_file_grp": [
        "OCR-D-IMG-PAGE"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
        "feature_filter": {
          "type": "string",
          "default": "",
          "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`)."
        },
        "mimetype": {
          "type": "string",
          "enum": ["image/bmp", "application/postscript", "image/gif", "image/jpeg", "image/jp2", "image/png", "image/x-portable-pixmap", "image/tiff"],
          "default": "image/png",
          "description": "File format to save extracted images in."
        },
        "transparency": {
          "type": "boolean",
          "default": true,
          "description": "Add alpha channels with segment masks to the images"
        },
        "plot_overlay": {
          "type": "boolean",
          "default": false,
          "description": "When generating mask images with `plot_segmasks`, instead of starting with a blank image and having layers and segments replace each other, start with the raw image and superimpose (alpha-composite) layers and segments."
        },
        "plot_segmasks": {
          "type": "array",
          "items": {
            "type": "string",
            "enum": ["order", "page", "region", "line", "word", "glyph"]
          },
          "default": ["region"],
          "description": "Generate mask images of the page segmentation in the last output fileGrp. Draw filled polygons for each specified PAGE hierarchy level in the list (in that order), where 'page' denotes the Border polygon, 'region' denotes Region types, 'line' denotes TextLine, 'word' denotes Word and 'glyph' denotes Glyph. Each type must be mapped in `colordict`. Where neighbors of the same type intersect, show a warning (unless `plot_overlay` is true). If 'order' is present, then draw arrows for reading order, too."
        },
        "colordict": {
          "type": "object",
          "default": {
            "":                                     "FFFFFF00",
            "ReadingOrderLevel0":                   "DC143CFF",
            "ReadingOrderLevel1":                   "9400D3FF",
            "ReadingOrderLevelN":                   "8B0000FF",
            "Border":                               "FFFFFFFF",
            "TableRegion":                          "8B4513FF",
            "AdvertRegion":                         "4682B4FF",
            "ChemRegion":                           "FF8C00FF",
            "MusicRegion":                          "9400D3FF",
            "MapRegion":                            "9ACDD2FF",
            "TextRegion":                           "0000FFFF",
            "TextRegion:paragraph":                 "0000FFFA",
            "TextRegion:heading":                   "0000FFF5",
            "TextRegion:caption":                   "0000FFF0",
            "TextRegion:header":                    "0000FFEB",
            "TextRegion:footer":                    "0000FFE6",
            "TextRegion:page-number":               "0000FFE1",
            "TextRegion:drop-capital":              "0000FFDC",
            "TextRegion:credit":                    "0000FFD7",
            "TextRegion:floating":                  "0000FFD2",
            "TextRegion:signature-mark":            "0000FFCD",
            "TextRegion:catch-word":                "0000FFC8",
            "TextRegion:marginalia":                "0000FFC3",
            "TextRegion:footnote":                  "0000FFBE",
            "TextRegion:footnote-continued":        "0000FFB9",
            "TextRegion:endnote":                   "0000FFB4",
            "TextRegion:TOC-entry":                 "0000FFAF",
            "TextRegion:list-label":                "0000FFA5",
            "TextRegion:other":                     "0000FFA0",
            "ChartRegion":                          "800080FF",
            "ChartRegion:bar":                      "800080FA",
            "ChartRegion:line":                     "800080F5",
            "ChartRegion:pie":                      "800080F0",
            "ChartRegion:scatter":                  "800080EB",
            "ChartRegion:surface":                  "800080E6",
            "ChartRegion:other":                    "800080E1",
            "GraphicRegion":                        "008000FF",
            "GraphicRegion:logo":                   "008000FA",
            "GraphicRegion:letterhead":             "008000F0",
            "GraphicRegion:decoration":             "008000EB",
            "GraphicRegion:frame":                  "008000E6",
            "GraphicRegion:handwritten-annotation": "008000E1",
            "GraphicRegion:stamp":                  "008000DC",
            "GraphicRegion:signature":              "008000D7",
            "GraphicRegion:barcode":                "008000D2",
            "GraphicRegion:paper-grow":             "008000CD",
            "GraphicRegion:punch-hole":             "008000C8",
            "GraphicRegion:other":                  "008000C3",
            "ImageRegion":                          "00CED1FF",
            "LineDrawingRegion":                    "B8860BFF",
            "MathsRegion":                          "00BFFFFF",
            "NoiseRegion":                          "FF0000FF",
            "SeparatorRegion":                      "FF00FFFF",
            "UnknownRegion":                        "646464FF",
            "CustomRegion":                         "637C81FF",
            "TextLine":                             "32CD32FF",
            "Word":                                 "B22222FF",
            "Glyph":                                "2E8B08FF"},
          "description": "Mapping from segment types to extract to color values in the output mask images and COCO; color must be encoded hexadecimal (e.g. '00FF00'); region type equals the element name in PAGE-XML, optionally followed by a colon and a subtype (e.g. 'TextRegion:paragraph'; unmapped region types will be ignored (i.e. treated as background)). Default is PageViewer color scheme. Cf. colordict parameter of ocrd-segment-from-masks."
        }
      }
    },
    "ocrd-segment-extract-regions": {
      "executable": "ocrd-segment-extract-regions",
      "categories": ["Image preprocessing"],
      "description": "Extract region segmentation as region images (deskewed according to `*/@orientation` and cropped+masked along `*/Coords` polygon) + JSON (including region coordinates/classes and meta-data).",
      "input_file_grp": [
        "OCR-D-SEG-BLOCK",
        "OCR-D-GT-SEG-BLOCK"
      ],
      "output_file_grp": [
        "OCR-D-IMG-REGION"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
        "feature_filter": {
          "type": "string",
          "default": "",
          "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`)."
        },
        "mimetype": {
          "type": "string",
          "enum": ["image/bmp", "application/postscript", "image/gif", "image/jpeg", "image/jp2", "image/png", "image/x-portable-pixmap", "image/tiff"],
          "default": "image/png",
          "description": "File format to save extracted images in."
        },
        "transparency": {
          "type": "boolean",
          "default": true,
          "description": "Add alpha channels with segment masks to the images"
        }
      }
    },
    "ocrd-segment-extract-lines": {
      "executable": "ocrd-segment-extract-lines",
      "categories": ["Image preprocessing"],
      "description": "Extract line segmentation as line images + text file + JSON.",
      "input_file_grp": [
        "OCR-D-SEG-LINE",
        "OCR-D-GT-SEG-LINE"
      ],
      "output_file_grp": [
        "OCR-D-IMG-LINE"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
        "feature_filter": {
          "type": "string",
          "default": "",
          "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`)."
        },
        "mimetype": {
          "type": "string",
          "enum": ["image/bmp", "application/postscript", "image/gif", "image/jpeg", "image/jp2", "image/png", "image/x-portable-pixmap", "image/tiff"],
          "default": "image/png",
          "description": "File format to save extracted images in."
        },
        "transparency": {
          "type": "boolean",
          "default": true,
          "description": "Add alpha channels with segment masks to the images"
        },
        "output-types": {
          "type": "array",
          "default": ["text", "json", "xlsx"],
          "items": {
            "type": "string",
            "enum": ["text", "json", "xlsx"]
          },
          "description": "What kind of files to extract besides the line image itself (text/json files for  each line, xlsx per page)."
        },
        "library-convention": {
          "type": "string",
          "enum": ["slub", "sbb", "none"],
          "default": "none",
          "description": "For xlsx extraction, to make line images hyperlinked, use this scheme in reconstructing presentation URLs of original pages. Libraries have different conventions in their METS files. Set to none to disable."
        },
        "min-line-length": {
          "type": "number",
          "format": "integer",
          "minimum": 0,
          "default": 0,
          "description": "Only extract lines with at least this many characters."
        },
        "min-line-width": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 1,
          "description": "Only extract lines that are at least this wide (in px)."
        },
        "min-line-height": {
          "type": "number",
          "format": "integer",
          "minimum": 1,
          "default": 1,
          "description": "Only extract lines that are at least this high (in px)."
        }
      }
    },
    "ocrd-segment-extract-words": {
      "executable": "ocrd-segment-extract-words",
      "categories": ["Image preprocessing"],
      "description": "Extract word segmentation as word images (deskewed according to `*/@orientation` and cropped+masked along `*/Coords` polygon and dewarped as in `*/AlternativeImage`) + text file (according to `*/TextEquiv`) + JSON (including line coordinates and meta-data).",
      "input_file_grp": [
        "OCR-D-SEG-WORD",
        "OCR-D-GT-SEG-WORD"
      ],
      "output_file_grp": [
        "OCR-D-IMG-WORD"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
        "feature_filter": {
          "type": "string",
          "default": "",
          "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`)."
        },
        "mimetype": {
          "type": "string",
          "enum": ["image/bmp", "application/postscript", "image/gif", "image/jpeg", "image/jp2", "image/png", "image/x-portable-pixmap", "image/tiff"],
          "default": "image/png",
          "description": "File format to save extracted images in."
        },
        "transparency": {
          "type": "boolean",
          "default": true,
          "description": "Add alpha channels with segment masks to the images"
        }
      }
    },
    "ocrd-segment-extract-glyphs": {
      "executable": "ocrd-segment-extract-glyphs",
      "categories": ["Image preprocessing"],
      "description": "Extract glyph segmentation as glyph images (deskewed according to `*/@orientation` and cropped+masked along `*/Coords` polygon and dewarped as in `*/AlternativeImage`) + text file (according to `*/TextEquiv`) + JSON (including line coordinates and meta-data).",
      "input_file_grp": [
        "OCR-D-SEG-GLYPH",
        "OCR-D-GT-SEG-GLYPH"
      ],
      "output_file_grp": [
        "OCR-D-IMG-GLYPH"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
        "feature_filter": {
          "type": "string",
          "default": "",
          "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`)."
        },
        "mimetype": {
          "type": "string",
          "enum": ["image/bmp", "application/postscript", "image/gif", "image/jpeg", "image/jp2", "image/png", "image/x-portable-pixmap", "image/tiff"],
          "default": "image/png",
          "description": "File format to save extracted images in."
        },
        "transparency": {
          "type": "boolean",
          "default": true,
          "description": "Add alpha channels with segment masks to the images"
        }
      }
    },
    "ocrd-segment-replace-original": {
      "executable": "ocrd-segment-replace-original",
      "categories": ["Image preprocessing"],
      "description": "Extract page image (deskewed according to `/Page/@orientation` and cropped+masked along `/Page/Border`) and use it as @imageFilename, adjusting all coordinates",
      "input_file_grp": [
        "OCR-D-SEG-LINE",
        "OCR-D-GT-SEG-LINE",
        "OCR-D-OCR"
      ],
      "output_file_grp": [
        "OCR-D-SEG-CROP"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
          "feature_selector": {
              "type": "string",
              "default": "",
              "description": "Comma-separated list of required image features (e.g. `binarized,despeckled`)"
          },
          "feature_filter": {
              "type": "string",
              "default": "",
              "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`)"
          },
          "transform_coordinates": {
              "type": "boolean",
              "default": true,
              "description": "re-calculate coordinates for all segments of the structural hierarchy to be consistent with the coordinate system of the chosen image again (vital after cropping, deskewing etc; disable only if input coordinates must be assumed to be inconsistent with the original)"
          }
      }
    },
    "ocrd-segment-replace-page": {
      "executable": "ocrd-segment-replace-page",
      "categories": ["Image preprocessing"],
      "description": "Replace everything below page level with another annotation, adjusting all coordinates",
      "input_file_grp": [
        "OCR-D-SEG-LINE",
        "OCR-D-GT-SEG-LINE",
        "OCR-D-OCR"
      ],
      "output_file_grp": [
        "OCR-D-SEG-LINE",
        "OCR-D-OCR"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
          "transform_coordinates": {
              "type": "boolean",
              "default": true,
              "description": "re-calculate coordinates for all segments of the structural hierarchy to be consistent with the coordinate system of the first input file group (vital after cropping, deskewing etc; disable only if input coordinates can be assumed to be consistent with the second input file group)"
          }
      }
    },
    "ocrd-segment-evaluate": {
      "executable": "ocrd-segment-evaluate",
      "categories": ["Layout analysis"],
      "description": "Compare segmentations",
      "input_file_grp": [
        "OCR-D-GT-SEG-BLOCK",
        "OCR-D-SEG-BLOCK"
      ],
      "steps": ["layout/analysis"],
      "parameters": {
        "level-of-operation": {
          "type": "string",
          "enum": ["region", "line"],
          "default": "region",
          "description": "segment hierarchy level to compare GT and predictions at"
        },
        "only-fg": {
          "type": "boolean",
          "default": false,
          "description": "only overlap and compare the foregrounds in the binarized image"
        },
        "ignore-subtype": {
          "type": "boolean",
          "default": false,
          "description": "on region level, ignore @type differentiation (where applicable)"
        },
        "for-categories": {
          "type": "string",
          "default": "",
          "description": "on region level, only compare these region types (comma-separated list; unless `ignore-subtype` is given, append subtypes via `.`; e.g. `TextRegion.page-number,TextRegion.marginalia`)"
        }
      }
    }
  }
}
